{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7daddd5-158e-4aaa-b133-dbca398e43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03fc3abf-10ff-4e5c-8bc7-c2a25b3bb2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "testX = testX.reshape(-1, 28 * 28).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ebaeda0-21fe-4799-88b1-de325bfc3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we implement a fully very simple fully connected neural network right from scratch\n",
    "\n",
    "There are two hidden layers each with 16 neurons\n",
    "One input layer and one output layer\n",
    "Note that we used this neural network only as a small example\n",
    "Hence necessarily our accuracy will be less. In order to show that we don't really\n",
    "perform worse than a pre-defined library like tensor flow we implemented the same net in keras and\n",
    "tested the neural net and as it turns out at the end, our accuracy of the algorithm and neural network we\n",
    "wrote from scratch gives better accuracy than given by tensorflow on the same network\n",
    "\n",
    "The function followed is the sigmoid function but can be changed easily in func definition\n",
    "Biases and weights are maintained in vectors and matrices respectively\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "def derivative(x):\n",
    "    delta = 0.000000000001\n",
    "    return ((func(x+delta) - func(x-delta))/(2*delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e39997b4-e0d1-43cb-9b14-31608b407146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biases\n",
    "b_l1 = np.zeros(16) # bias of 1st hidden layer\n",
    "b_l2 = np.zeros(16) # bias of 2nd hidden layer\n",
    "b_o = np.zeros(10) # bias of output layer\n",
    "\n",
    "#weights\n",
    "w_i_l1 = np.zeros((784,16)) # weights of edges between input layer and 1st hidden layer\n",
    "w_l1_l2 = np.zeros((16,16)) # weights of edges between 1st hidden layer and 2nd hidden layer\n",
    "w_l2_o = np.zeros((16,10)) # weights of edges between 1st hidden layer and output layer\n",
    "\n",
    "#inputs to each layer\n",
    "i_l1 = np.zeros(16) # biased input to 1st hidden layer\n",
    "i_l2 = np.zeros(16) # biased input to 2nd hidden layer\n",
    "i_o = np.zeros(10) # biased input to output layer\n",
    "\n",
    "#outputs to each layer\n",
    "o_l1 = np.zeros(16) # output of 1st hidden layer after biases applied\n",
    "o_l2 = np.zeros(16) # output of 2nd hidden layer after biases applied\n",
    "o_o = np.zeros(10) # output of output layer after biases applied\n",
    "\n",
    "#error function\n",
    "er = np.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf3d9486-763d-45cc-afdb-67410dc84e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_i_l1(idx,data):\n",
    "    for i in range(16):\n",
    "        i_l1[i] = b_l1[i]\n",
    "        for j in range(784):\n",
    "            i_l1[i] += w_i_l1[j][i]*data[idx][j]\n",
    "\n",
    "def eval_o_l1(idx,data):\n",
    "    eval_i_l1(idx,data)\n",
    "    for i in range(16):\n",
    "        o_l1[i] = func(i_l1[i])\n",
    "\n",
    "def eval_i_l2(idx,data):\n",
    "    eval_o_l1(idx,data)\n",
    "    for i in range(16):\n",
    "        i_l2[i] = b_l2[i]\n",
    "        for j in range(16):\n",
    "            i_l2[i] += w_l1_l2[j][i]*o_l1[j]\n",
    "\n",
    "def eval_o_l2(idx,data):\n",
    "    eval_i_l2(idx,data)\n",
    "    for i in range(16):\n",
    "        o_l2[i] = func(i_l2[i])\n",
    "\n",
    "def eval_i_o(idx,data):\n",
    "    eval_o_l2(idx,data)\n",
    "    for i in range(10):\n",
    "        i_o[i] = b_o[i]\n",
    "        for j in range(16):\n",
    "            i_o[i] += w_l2_o[j][i]*o_l2[j]\n",
    "\n",
    "\n",
    "def eval_o_o(idx,data):\n",
    "    eval_i_o(idx,data)\n",
    "    for i in range(10):\n",
    "        o_o[i] = func(i_o[i])\n",
    "\n",
    "def eval_model(idx,data):\n",
    "    eval_o_o(idx,data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2de95d8b-f512-4583-9c61-6d952e27d42f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "801c295d-40ca-4f2c-bbbf-7f1a0cc298ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying backpropagation algorithm\n",
    "\n",
    "deriv_bo = np.zeros(10)\n",
    "deriv_w_2o = np.zeros((16,10))\n",
    "deriv_b2 = np.zeros(16)\n",
    "deriv_w_12 = np.zeros((16,16))\n",
    "deriv_b1 = np.zeros(16)\n",
    "deriv_w_i1 = np.zeros((784,16))\n",
    "\n",
    "\n",
    "# apply dynamic programming to evaluate derivative\n",
    "# each successive derivative arrays depends on the previous thereby\n",
    "# minimizing calculation by calculating reduntant terms only once\n",
    "\n",
    "def eval_bo(idx):\n",
    "    for i in range(10):\n",
    "        deriv_bo[i] = derivative(i_o[i])*(o_o[i])\n",
    "    #print(\"$ \"+str(derivative(i_o[i])) + \" # \" + str(i_o[i]))\n",
    "    deriv_bo[trainY[idx]] -= derivative(i_o[trainY[idx]])\n",
    "\n",
    "def eval_w_2o():\n",
    "    for j in range(16):\n",
    "        for i in range(10):\n",
    "            deriv_w_2o[j][i] = o_l2[j]*deriv_bo[i]\n",
    "\n",
    "def eval_b2():\n",
    "    for i in range(16):\n",
    "        deriv_b2[i] = 0\n",
    "        for j in range(10):\n",
    "            deriv_b2[i] += derivative(i_l2[i])*w_l2_o[i][j]*deriv_bo[j]\n",
    "\n",
    "def eval_w_12():\n",
    "    for j in range(16):\n",
    "        for i in range(16):\n",
    "            deriv_w_12[j][i] = o_l1[j]*deriv_b2[i]\n",
    "\n",
    "def eval_b1():\n",
    "    for i in range(16):\n",
    "        deriv_b1[i] = 0\n",
    "        for k in range(16):\n",
    "            deriv_b1[i] += deriv_b2[k]*w_l1_l2[i][k]*derivative(i_l1[i])\n",
    "\n",
    "def eval_w_i1(idx):\n",
    "    for j in range(784):\n",
    "        for i in range(16):\n",
    "            deriv_w_i1[j][i] = deriv_b1[i]*trainX[idx][j]\n",
    "\n",
    "\n",
    "def eval_grads(idx):\n",
    "    eval_bo(idx)\n",
    "    eval_w_2o()\n",
    "    eval_b2()\n",
    "    eval_w_12()\n",
    "    eval_b1()\n",
    "    eval_w_i1(idx)\n",
    "\n",
    "def mini_batch_vanilla_descent(lr,batch_size): #lr = learning rate\n",
    "    indices = np.random.randint(0,trainX.shape[0],batch_size)\n",
    "    \n",
    "    # average gradient vectors or matrixes\n",
    "    avgd_bo = np.zeros(10)\n",
    "    avgd_w_2o = np.zeros((16,10))\n",
    "    avgd_b2 = np.zeros(16)\n",
    "    avgd_w_12 = np.zeros((16,16))\n",
    "    avgd_b1 = np.zeros(16)\n",
    "    avgd_w_i1 = np.zeros((784,16))\n",
    "    \n",
    "    for idx in indices:\n",
    "        eval_model(idx,trainX)\n",
    "        eval_grads(idx)\n",
    "        \n",
    "        # compute average gradient from batch\n",
    "        for i in range(10):\n",
    "            avgd_bo[i] += deriv_bo[i]/batch_size\n",
    "        \n",
    "        for i in range(16):\n",
    "            for j in range(10):\n",
    "                avgd_w_2o[i][j] += deriv_w_2o[i][j]/batch_size\n",
    "                \n",
    "        for i in range(16):\n",
    "            avgd_b2[i] += deriv_b2[i]/batch_size\n",
    "\n",
    "        for i in range(16):\n",
    "            for j in range(16):\n",
    "                avgd_w_12[i][j] += deriv_w_12[i][j]/batch_size\n",
    "        \n",
    "        for i in range(16):\n",
    "            avgd_b1[i] += deriv_b1[i]/batch_size\n",
    "        \n",
    "        for i in range(784):\n",
    "            for j in range(16):\n",
    "                avgd_w_i1[i][j] += deriv_w_i1[i][j]/batch_size\n",
    "        \n",
    "        # now apply gradient descent\n",
    "        for i in range(10):\n",
    "            b_o[i] -= avgd_bo[i]*lr\n",
    "        \n",
    "        for i in range(16):\n",
    "            for j in range(10):\n",
    "                w_l2_o[i][j] -= avgd_w_2o[i][j]*lr\n",
    "                \n",
    "        for i in range(16):\n",
    "            b_l2[i] -= avgd_b2[i]*lr\n",
    "\n",
    "        for i in range(16):\n",
    "            for j in range(16):\n",
    "                w_l1_l2[i][j] -= avgd_w_12[i][j]*lr\n",
    "        \n",
    "        for i in range(16):\n",
    "            b_l1[i] -= avgd_b1[i]*lr\n",
    "        \n",
    "        for i in range(784):\n",
    "            for j in range(16):\n",
    "                w_i_l1[i][j] -= avgd_w_i1[i][j]*lr\n",
    "        \n",
    "    #print(deriv_bo[1:6])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "194a7c8b-ccfd-4e1e-84ef-56404314a448",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab14ab76-e7be-45e6-b773-8afc12eafdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_vanilla_gradient_descent_iterator(lr,batch_size,iterations):\n",
    "    for i in range(iterations):\n",
    "        mini_batch_vanilla_descent(lr,batch_size)\n",
    "        if((i)%(iterations//50)==0): \n",
    "            print(str(i+1)+\" iterations done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab2d6a28-41c8-48f2-bbe4-caeedd051e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iterations done!\n",
      "21 iterations done!\n",
      "41 iterations done!\n",
      "61 iterations done!\n",
      "81 iterations done!\n",
      "101 iterations done!\n",
      "121 iterations done!\n",
      "141 iterations done!\n",
      "161 iterations done!\n",
      "181 iterations done!\n",
      "201 iterations done!\n",
      "221 iterations done!\n",
      "241 iterations done!\n",
      "261 iterations done!\n",
      "281 iterations done!\n",
      "301 iterations done!\n",
      "321 iterations done!\n",
      "341 iterations done!\n",
      "361 iterations done!\n",
      "381 iterations done!\n",
      "401 iterations done!\n",
      "421 iterations done!\n",
      "441 iterations done!\n",
      "461 iterations done!\n",
      "481 iterations done!\n",
      "501 iterations done!\n",
      "521 iterations done!\n",
      "541 iterations done!\n",
      "561 iterations done!\n",
      "581 iterations done!\n",
      "601 iterations done!\n",
      "621 iterations done!\n",
      "641 iterations done!\n",
      "661 iterations done!\n",
      "681 iterations done!\n",
      "701 iterations done!\n",
      "721 iterations done!\n",
      "741 iterations done!\n",
      "761 iterations done!\n",
      "781 iterations done!\n",
      "801 iterations done!\n",
      "821 iterations done!\n",
      "841 iterations done!\n",
      "861 iterations done!\n",
      "881 iterations done!\n",
      "901 iterations done!\n",
      "921 iterations done!\n",
      "941 iterations done!\n",
      "961 iterations done!\n",
      "981 iterations done!\n",
      "1000 iterations done! finally\n"
     ]
    }
   ],
   "source": [
    "# applying mini-batch gradient descent using backpropagation algorithm\n",
    "iterations = 1000\n",
    "mini_batch_vanilla_gradient_descent_iterator(10,10,iterations)\n",
    "print(str(iterations) +  \" iterations done! finally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0a0a147-f847-4315-bf20-093bcc1950bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc():\n",
    "    cnt = 0\n",
    "    indices = np.random.randint(0,testX.shape[0],1000) #choosing 1000 test samples randomly for testing\n",
    "    #print(testX.shape[0])\n",
    "    for idx in indices:\n",
    "        #print(\"testing for \"+str(idx+1)+\"th sample\")\n",
    "        eval_model(idx,testX)\n",
    "        probablility = 0\n",
    "        prediction = -1\n",
    "        for i in range(10):\n",
    "            #print(o_o[i])\n",
    "            if(probablility < o_o[i]):\n",
    "                probablility = o_o[i]\n",
    "                prediction = i\n",
    "        #print(\"------\")\n",
    "        #print(testY[idx])\n",
    "        #print(prediction)\n",
    "        if(testY[idx]==prediction):\n",
    "            cnt += 1\n",
    "    return cnt/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a73d479-3877-44f4-adc8-299e40a90a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of My_Neural_Net from code written from scratch : 0.197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc1 = eval_acc()\n",
    "f = open(\"output_2.txt\",\"w\")\n",
    "f.write(\"Accuracy of MyNet from code written from scratch : \"+str(acc1)+'\\n')\n",
    "print(\"Accuracy of My_Neural_Net from code written from scratch : \"+str(acc1)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f83b986a-71a9-4cc3-8bad-0a41e47cdc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LAYER_1 (Dense)             (None, 16)                12560     \n",
      "                                                                 \n",
      " LAYER_2 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " OUTPUT (Dense)              (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 20.3280 - accuracy: 0.0983\n",
      "313/313 [==============================] - 0s 995us/step - loss: 20.2422 - accuracy: 0.0980\n",
      "Accuracy of My_Neural_Net using standard library : 0.09799999743700027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MyNet = tf.keras.Sequential()\n",
    "MyNet.add(keras.layers.InputLayer(784))\n",
    "MyNet.add(layers.Dense(16, activation='sigmoid', name='LAYER_1'))\n",
    "MyNet.add(layers.Dense(16, activation='sigmoid', name='LAYER_2'))\n",
    "MyNet.add(layers.Dense(10, activation='sigmoid', name='OUTPUT'))\n",
    "\n",
    "MyNet.summary()\n",
    "\n",
    "MyNet.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "MyNet.fit(trainX, trainY, batch_size=10)\n",
    "acc = MyNet.evaluate(testX, testY)[1]\n",
    "f.write(\"Accuracy of MyNet using standard library : \"+str(acc)+'\\n')\n",
    "print(\"Accuracy of My_Neural_Net using standard library : \"+str(acc)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c3172-5ee4-4a12-b25c-b55462267790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
